{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read training data\n",
    "training_binary = pd.read_csv(\"../input/training_binary.csv\")\n",
    "y_train = training_binary['cuisine']\n",
    "x_train = training_binary.drop(['cuisine', 'id'],axis=1)\n",
    "\n",
    "# Read test data\n",
    "test_binary = pd.read_csv(\"../input/test_binary.csv\")\n",
    "y_test = test_binary['cuisine']\n",
    "x_test = test_binary.drop(['cuisine', 'id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create logistic classifier using default parameters\n",
    "clf = LogisticRegression()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Confusing matrix training data default parameters\n",
    "training_predictions = clf.predict(x_train)\n",
    "cm = pd.DataFrame(confusion_matrix(y_train,training_predictions,labels=list(set(y_train))),index=list(set(y_train)),columns=list(set(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance results using default parameters\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_train, training_predictions)))\n",
    "print(\"Number of inequalities: {}\\n\".format((y_train!=training_predictions).sum()))\n",
    "\n",
    "# Precision\n",
    "print(\"Average precision rate: {}\".format(precision_score(y_train, training_predictions, average='micro')))\n",
    "\n",
    "# Recall\n",
    "print(\"Average recall rate: {}\".format(recall_score(y_train, training_predictions, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_params = {\n",
    "    'C': [0.001,0.01,0.1,1,10,100],\n",
    "    'penalty': ['l1','l2']\n",
    "}\n",
    "\n",
    "gridsearch = GridSearchCV(LogisticRegression(), grid_params)\n",
    "gridsearch.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(gridsearch.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C = 1, penalty='l2')\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Confusing matrix training data gridsearch found parameters\n",
    "training_predictions = clf.predict(x_train)\n",
    "cm_training = pd.DataFrame(confusion_matrix(y_train,training_predictions,labels=list(set(y_train))),index=list(set(y_train)),columns=list(set(y_train)))\n",
    "\n",
    "# Confusing matrix test data gridsearch found parameters\n",
    "test_predictions = clf.predict(x_test)\n",
    "cm_test = pd.DataFrame(confusion_matrix(y_test,test_predictions,labels=list(set(y_test))),index=list(set(y_test)),columns=list(set(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training confusion matrix\n",
    "cm_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy on training set: {}\".format(accuracy_score(y_train, training_predictions)))\n",
    "print(\"Precision on training set: {}\".format(precision_score(y_train, training_predictions, average='micro')))\n",
    "print(\"Recall on training set: {}\".format(recall_score(y_train, training_predictions, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test confusion matrix\n",
    "cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy on test set: {}\".format(accuracy_score(y_test, test_predictions)))\n",
    "print(\"Precision on test set: {}\".format(precision_score(y_test, test_predictions, average='micro')))\n",
    "print(\"Recall on test set: {}\".format(recall_score(y_test, test_predictions, average='micro')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
